#!/usr/bin/env python3
"""
AQI é æ¸¬ç³»çµ± - çµ±ä¸€è¨“ç·´åŸ·è¡Œè…³æœ¬
æ”¯æ´5ç¨®æ¨™æº–åŒ–è¨“ç·´æ¨¡å¼ï¼Œç§»é™¤æ¡ƒåœ’å°ˆç”¨ä»£ç¢¼ï¼Œç¬¦åˆç ”ç©¶æ¨™æº–
"""

import os
import sys
import logging
import argparse
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# å°å…¥çµ±ä¸€é…ç½®å’Œæ¨¡çµ„
from src.unified_config import (
    UnifiedConfig, ConfigFactory, validate_research_standards,
    ALL_MODES, STATION_REQUIRED_MODES, GLOBAL_MODES
)
from src.unified_preprocessor import preprocess_data_by_mode, batch_preprocess
from src.unified_window_generator import generate_windows_by_mode, batch_generate_windows
from src.unified_trainer import train_models_by_mode, batch_train_models

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(f'unified_training_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

def detect_available_stations() -> List[str]:
    """æª¢æ¸¬å¯ç”¨çš„æ¸¬ç«™"""
    stations = set()
    
    # å¾åŸå§‹æ•¸æ“šç›®éŒ„æª¢æ¸¬
    separate_dir = Path("data/raw/Separate")
    if separate_dir.exists():
        for file in separate_dir.glob("*_combined.csv"):
            station = file.stem.split('_')[0]
            stations.add(station)
    
    separate_norm_dir = Path("data/raw/Separate_Nomorlization")
    if separate_norm_dir.exists():
        for file in separate_norm_dir.glob("*_combined.csv"):
            station = file.stem.split('_')[0]
            stations.add(station)
    
    return sorted(list(stations))

def run_mode_combine(mode: str) -> Dict:
    """é‹è¡Œåˆä½µæ¨¡å¼ï¼ˆcombine æˆ– combine_normï¼‰"""
    logger.info(f"=" * 60)
    logger.info(f"é–‹å§‹åŸ·è¡Œæ¨¡å¼: {mode}")
    logger.info(f"=" * 60)
    
    try:
        # æ­¥é©Ÿ1: æ•¸æ“šé è™•ç†
        logger.info("æ­¥é©Ÿ1: æ•¸æ“šé è™•ç†")
        preprocess_result = preprocess_data_by_mode(mode)
        logger.info("âœ… æ•¸æ“šé è™•ç†å®Œæˆ")
        
        # æ­¥é©Ÿ2: æ™‚é–“çª—å£ç”Ÿæˆ
        logger.info("æ­¥é©Ÿ2: æ™‚é–“çª—å£ç”Ÿæˆ")
        windows_result = generate_windows_by_mode(mode)
        logger.info("âœ… æ™‚é–“çª—å£ç”Ÿæˆå®Œæˆ")
        
        # æ­¥é©Ÿ3: æ¨¡å‹è¨“ç·´
        logger.info("æ­¥é©Ÿ3: æ¨¡å‹è¨“ç·´")
        training_result = train_models_by_mode(mode)
        logger.info("âœ… æ¨¡å‹è¨“ç·´å®Œæˆ")
        
        return {
            'status': 'success',
            'mode': mode,
            'preprocess': preprocess_result,
            'windows': windows_result,
            'training': training_result
        }
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å¼ {mode} åŸ·è¡Œå¤±æ•—: {e}")
        return {
            'status': 'failed',
            'mode': mode,
            'error': str(e)
        }

def run_mode_separate(mode: str, stations: Optional[List[str]] = None) -> Dict:
    """é‹è¡Œåˆ†é›¢æ¨¡å¼ï¼ˆseparate æˆ– separate_normï¼‰"""
    logger.info(f"=" * 60)
    logger.info(f"é–‹å§‹åŸ·è¡Œæ¨¡å¼: {mode}")
    logger.info(f"=" * 60)
    
    if stations is None:
        stations = detect_available_stations()
    
    if not stations:
        return {
            'status': 'failed',
            'mode': mode,
            'error': 'æœªæª¢æ¸¬åˆ°å¯ç”¨çš„æ¸¬ç«™æ•¸æ“š'
        }
    
    logger.info(f"è™•ç† {len(stations)} å€‹æ¸¬ç«™: {stations}")
    
    try:
        # æ‰¹é‡è™•ç†æ‰€æœ‰æ­¥é©Ÿ
        logger.info("æ­¥é©Ÿ1: æ‰¹é‡æ•¸æ“šé è™•ç†")
        preprocess_results = batch_preprocess([mode], stations)
        logger.info("âœ… æ‰¹é‡æ•¸æ“šé è™•ç†å®Œæˆ")
        
        logger.info("æ­¥é©Ÿ2: æ‰¹é‡æ™‚é–“çª—å£ç”Ÿæˆ")
        windows_results = batch_generate_windows([mode], stations)
        logger.info("âœ… æ‰¹é‡æ™‚é–“çª—å£ç”Ÿæˆå®Œæˆ")
        
        logger.info("æ­¥é©Ÿ3: æ‰¹é‡æ¨¡å‹è¨“ç·´")
        training_results = batch_train_models([mode], stations)
        logger.info("âœ… æ‰¹é‡æ¨¡å‹è¨“ç·´å®Œæˆ")
        
        # çµ±è¨ˆæˆåŠŸå¤±æ•—
        successful = []
        failed = []
        
        for station in stations:
            key = f"{mode}_{station}"
            if key in training_results and isinstance(training_results[key], dict) and 'error' not in training_results[key]:
                successful.append(station)
            else:
                failed.append(station)
        
        return {
            'status': 'success' if not failed else 'partial',
            'mode': mode,
            'total_stations': len(stations),
            'successful_stations': successful,
            'failed_stations': failed,
            'preprocess': preprocess_results,
            'windows': windows_results,
            'training': training_results
        }
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å¼ {mode} åŸ·è¡Œå¤±æ•—: {e}")
        return {
            'status': 'failed',
            'mode': mode,
            'error': str(e)
        }

def run_mode_station_specific(target_stations: List[str]) -> Dict:
    """é‹è¡ŒæŒ‡å®šæ¸¬ç«™æ¨¡å¼"""
    logger.info(f"=" * 60)
    logger.info(f"é–‹å§‹åŸ·è¡ŒæŒ‡å®šæ¸¬ç«™æ¨¡å¼: {target_stations}")
    logger.info(f"=" * 60)
    
    available_stations = detect_available_stations()
    invalid_stations = [s for s in target_stations if s not in available_stations]
    
    if invalid_stations:
        return {
            'status': 'failed',
            'error': f'æŒ‡å®šçš„æ¸¬ç«™ä¸å¯ç”¨: {invalid_stations}. å¯ç”¨æ¸¬ç«™: {available_stations}'
        }
    
    results = {}
    
    for station in target_stations:
        logger.info(f"è™•ç†æ¸¬ç«™: {station}")
        
        for mode in ['separate', 'separate_norm']:
            mode_key = f"{station}_{mode}"
            logger.info(f"  åŸ·è¡Œæ¨¡å¼: {mode}")
            
            try:
                # å®Œæ•´æµç¨‹
                preprocess_result = preprocess_data_by_mode(mode, station)
                windows_result = generate_windows_by_mode(mode, station)
                training_result = train_models_by_mode(mode, station)
                
                results[mode_key] = {
                    'status': 'success',
                    'station': station,
                    'mode': mode,
                    'preprocess': preprocess_result,
                    'windows': windows_result,
                    'training': training_result
                }
                logger.info(f"  âœ… {mode} å®Œæˆ")
                
            except Exception as e:
                logger.error(f"  âŒ {mode} å¤±æ•—: {e}")
                results[mode_key] = {
                    'status': 'failed',
                    'station': station,
                    'mode': mode,
                    'error': str(e)
                }
    
    successful = sum(1 for r in results.values() if r['status'] == 'success')
    
    return {
        'status': 'success' if successful == len(results) else 'partial',
        'target_stations': target_stations,
        'total_tasks': len(results),
        'successful_tasks': successful,
        'results': results
    }

def main():
    """ä¸»åŸ·è¡Œå‡½æ•¸"""
    parser = argparse.ArgumentParser(description='AQIé æ¸¬ç³»çµ± - çµ±ä¸€è¨“ç·´åŸ·è¡Œå™¨')
    
    parser.add_argument('--mode', choices=['all', 'combine', 'combine_norm', 'separate', 'separate_norm', 'station_specific'],
                       default='all', help='åŸ·è¡Œæ¨¡å¼')
    parser.add_argument('--stations', nargs='+', help='æŒ‡å®šæ¸¬ç«™åˆ—è¡¨')
    parser.add_argument('--validate', action='store_true', help='åƒ…é©—è­‰é…ç½®ä¸åŸ·è¡Œè¨“ç·´')
    
    args = parser.parse_args()
    
    logger.info("ğŸš€ AQIé æ¸¬ç³»çµ± - çµ±ä¸€è¨“ç·´é–‹å§‹")
    logger.info(f"åŸ·è¡Œæ¨¡å¼: {args.mode}")
    
    # æª¢æ¸¬å¯ç”¨æ¸¬ç«™
    available_stations = detect_available_stations()
    logger.info(f"å¯ç”¨æ¸¬ç«™: {available_stations}")
    
    if args.validate:
        # é©—è­‰æ¨¡å¼
        logger.info("ğŸ” é©—è­‰ç ”ç©¶æ¨™æº–é…ç½®...")
        
        modes_to_validate = ALL_MODES if args.mode == 'all' else [args.mode]
        
        for mode in modes_to_validate:
            if mode in STATION_REQUIRED_MODES:
                stations = args.stations or available_stations
                for station in stations:
                    config = UnifiedConfig(mode=mode, station=station)
                    validations = validate_research_standards(config)
                    logger.info(f"{mode}_{station}: {validations}")
            else:
                config = UnifiedConfig(mode=mode)
                validations = validate_research_standards(config)
                logger.info(f"{mode}: {validations}")
        
        return
    
    # åŸ·è¡Œè¨“ç·´
    results = {}
    start_time = datetime.now()
    
    try:
        if args.mode == 'all':
            # åŸ·è¡Œæ‰€æœ‰5ç¨®æ¨¡å¼
            logger.info("ğŸ¯ åŸ·è¡Œå®Œæ•´çš„5ç¨®æ¨™æº–åŒ–è¨“ç·´æ¨¡å¼")
            
            # æ¨¡å¼1: combine
            results['mode_1_combine'] = run_mode_combine('combine')
            
            # æ¨¡å¼2: combine_norm
            results['mode_2_combine_norm'] = run_mode_combine('combine_norm')
            
            # æ¨¡å¼3: separate (æ‰€æœ‰æ¸¬ç«™)
            results['mode_3_separate_all'] = run_mode_separate('separate')
            
            # æ¨¡å¼4: separate_norm (æ‰€æœ‰æ¸¬ç«™)
            results['mode_4_separate_norm_all'] = run_mode_separate('separate_norm')
            
            # æ¨¡å¼5: station_specific (å¦‚æœæŒ‡å®šäº†æ¸¬ç«™)
            if args.stations:
                results['mode_5_station_specific'] = run_mode_station_specific(args.stations)
        
        elif args.mode in ['combine', 'combine_norm']:
            results[args.mode] = run_mode_combine(args.mode)
        
        elif args.mode in ['separate', 'separate_norm']:
            results[args.mode] = run_mode_separate(args.mode, args.stations)
        
        elif args.mode == 'station_specific':
            if not args.stations:
                logger.error("âŒ station_specific æ¨¡å¼éœ€è¦æŒ‡å®š --stations åƒæ•¸")
                return
            results['station_specific'] = run_mode_station_specific(args.stations)
        
        end_time = datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        
        # ç”Ÿæˆæ‘˜è¦
        logger.info("=" * 80)
        logger.info("ğŸ‰ åŸ·è¡Œå®Œæˆ!")
        logger.info(f"â±ï¸  ç¸½åŸ·è¡Œæ™‚é–“: {execution_time:.2f} ç§’")
        
        # çµ±è¨ˆçµæœ
        total_modes = len(results)
        successful_modes = sum(1 for r in results.values() if r.get('status') == 'success')
        
        logger.info(f"ğŸ“Š æˆåŠŸæ¨¡å¼: {successful_modes}/{total_modes}")
        
        for mode_name, result in results.items():
            status = result.get('status', 'unknown')
            if status == 'success':
                logger.info(f"  âœ… {mode_name}")
            elif status == 'partial':
                logger.info(f"  âš ï¸  {mode_name} (éƒ¨åˆ†æˆåŠŸ)")
            else:
                logger.info(f"  âŒ {mode_name} - {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
        
        # ä¿å­˜çµæœ
        output_file = f"unified_training_results_{start_time.strftime('%Y%m%d_%H%M%S')}.json"
        import json
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                'execution_info': {
                    'start_time': start_time.isoformat(),
                    'end_time': end_time.isoformat(),
                    'execution_time': execution_time,
                    'mode': args.mode,
                    'stations': args.stations,
                    'available_stations': available_stations
                },
                'results': results
            }, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"ğŸ“ çµæœå·²ä¿å­˜: {output_file}")
        logger.info("=" * 80)
        
    except Exception as e:
        logger.error(f"ğŸ’¥ åŸ·è¡Œéç¨‹ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 