#!/usr/bin/env python3
"""
AQIé æ¸¬ç³»çµ± - å ±å‘Šåˆ†æå™¨
èƒ½å¤ åˆ†æå’Œæ¯”è¼ƒæ‰€æœ‰è¨“ç·´å ±å‘Šï¼Œæä¾›æ·±åº¦æ´å¯Ÿ
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Any
import argparse
import warnings
warnings.filterwarnings('ignore')

# ä¸­æ–‡å­—é«”è¨­å®š
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei']
plt.rcParams['axes.unicode_minus'] = False

class ReportAnalyzer:
    """å ±å‘Šåˆ†æå™¨"""
    
    def __init__(self, reports_dir: str = "outputs/reports"):
        self.reports_dir = Path(reports_dir)
        self.data = []
        self.comparison_data = []
        
    def load_all_reports(self):
        """è¼‰å…¥æ‰€æœ‰JSONå ±å‘Š"""
        print("ğŸ” è¼‰å…¥å ±å‘Šæ•¸æ“š...")
        
        json_files = list(self.reports_dir.glob("*.json"))
        print(f"ç™¼ç¾ {len(json_files)} å€‹JSONå ±å‘Šæ–‡ä»¶")
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                if 'results' in data:
                    for result in data['results']:
                        if result.get('success', False):
                            self.data.append(result)
                            
            except Exception as e:
                print(f"âš ï¸ è¼‰å…¥ {json_file.name} å¤±æ•—: {e}")
                
        print(f"âœ… æˆåŠŸè¼‰å…¥ {len(self.data)} å€‹è¨“ç·´çµæœ")
        
    def create_comparison_dataframe(self) -> pd.DataFrame:
        """å‰µå»ºæ¯”è¼ƒç”¨çš„DataFrame"""
        comparison_data = []
        
        for item in self.data:
            base_info = {
                'pipeline_mode': item['pipeline_mode'],
                'station': item['station'],
                'timestamp': item['timestamp'],
                'success': item['success']
            }
            
            for model_name, model_data in item['models'].items():
                if model_data:  # ç¢ºä¿æ¨¡å‹æ•¸æ“šå­˜åœ¨
                    row = base_info.copy()
                    row['model'] = model_name
                    row['training_time'] = model_data.get('training_time', 0)
                    
                    # é©—è­‰é›†æŒ‡æ¨™
                    val_metrics = model_data.get('val_metrics', {})
                    row['val_mae'] = val_metrics.get('mae', np.nan)
                    row['val_rmse'] = val_metrics.get('rmse', np.nan)
                    row['val_mape'] = val_metrics.get('mape', np.nan)
                    row['val_r2'] = val_metrics.get('r2', np.nan)
                    
                    # è¨“ç·´é›†æŒ‡æ¨™
                    train_metrics = model_data.get('train_metrics', {})
                    row['train_mae'] = train_metrics.get('mae', np.nan)
                    row['train_rmse'] = train_metrics.get('rmse', np.nan)
                    row['train_mape'] = train_metrics.get('mape', np.nan)
                    row['train_r2'] = train_metrics.get('r2', np.nan)
                    
                    comparison_data.append(row)
        
        return pd.DataFrame(comparison_data)
    
    def analyze_model_performance(self, df: pd.DataFrame):
        """åˆ†ææ¨¡å‹æ€§èƒ½"""
        print("\n" + "="*60)
        print("ğŸ“Š æ¨¡å‹æ€§èƒ½åˆ†æ")
        print("="*60)
        
        # 1. æ•´é«”æ¨¡å‹æ¯”è¼ƒ
        print("\n1ï¸âƒ£ æ•´é«”æ¨¡å‹æ€§èƒ½æ¯”è¼ƒ")
        print("-" * 30)
        
        model_stats = df.groupby('model').agg({
            'val_mae': ['mean', 'std', 'min', 'max', 'count'],
            'val_r2': ['mean', 'std', 'min', 'max'],
            'training_time': ['mean', 'std', 'min', 'max']
        }).round(4)
        
        print(model_stats)
        
        # 2. æ¨¡å¼åˆ¥æ€§èƒ½æ¯”è¼ƒ
        print("\n2ï¸âƒ£ ä¸åŒè¨“ç·´æ¨¡å¼æ€§èƒ½æ¯”è¼ƒ")
        print("-" * 30)
        
        mode_stats = df.groupby(['pipeline_mode', 'model']).agg({
            'val_mae': 'mean',
            'val_r2': 'mean',
            'training_time': 'mean'
        }).round(4)
        
        print(mode_stats)
        
        # 3. æ‰¾å‡ºæœ€ä½³æ¨¡å‹çµ„åˆ
        print("\n3ï¸âƒ£ æœ€ä½³æ¨¡å‹çµ„åˆ")
        print("-" * 30)
        
        # ä¾æ“šMAEæ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_by_mae = df.loc[df['val_mae'].idxmin()]
        print(f"æœ€ä½MAE: {best_by_mae['station']} - {best_by_mae['model']} - {best_by_mae['pipeline_mode']}")
        print(f"MAE: {best_by_mae['val_mae']:.4f}, RÂ²: {best_by_mae['val_r2']:.4f}")
        
        # ä¾æ“šRÂ²æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_by_r2 = df.loc[df['val_r2'].idxmax()]
        print(f"æœ€é«˜RÂ²: {best_by_r2['station']} - {best_by_r2['model']} - {best_by_r2['pipeline_mode']}")
        print(f"MAE: {best_by_r2['val_mae']:.4f}, RÂ²: {best_by_r2['val_r2']:.4f}")
    
    def analyze_station_performance(self, df: pd.DataFrame):
        """åˆ†ææ¸¬ç«™æ€§èƒ½"""
        print("\n" + "="*60)
        print("ğŸ¢ æ¸¬ç«™æ€§èƒ½åˆ†æ")
        print("="*60)
        
        # 1. æ¸¬ç«™æ€§èƒ½æ’å
        station_stats = df.groupby('station').agg({
            'val_mae': 'mean',
            'val_r2': 'mean',
            'training_time': 'mean'
        }).round(4)
        
        # ä¾MAEæ’åº
        station_ranking = station_stats.sort_values('val_mae')
        print("\nğŸ“ˆ æ¸¬ç«™æ€§èƒ½æ’å (ä¾MAE)")
        print("-" * 30)
        print(station_ranking.head(10))
        
        # 2. è¡¨ç¾æœ€ä½³å’Œæœ€å·®çš„æ¸¬ç«™
        print(f"\nğŸ† è¡¨ç¾æœ€ä½³æ¸¬ç«™: {station_ranking.index[0]} (MAE: {station_ranking.iloc[0]['val_mae']:.4f})")
        print(f"ğŸ’” è¡¨ç¾æœ€å·®æ¸¬ç«™: {station_ranking.index[-1]} (MAE: {station_ranking.iloc[-1]['val_mae']:.4f})")
    
    def analyze_pipeline_modes(self, df: pd.DataFrame):
        """åˆ†æä¸åŒPipelineæ¨¡å¼çš„æ•ˆæœ"""
        print("\n" + "="*60)
        print("âš™ï¸ Pipelineæ¨¡å¼åˆ†æ")
        print("="*60)
        
        mode_comparison = df.groupby(['pipeline_mode', 'model']).agg({
            'val_mae': ['mean', 'count'],
            'val_r2': 'mean',
            'training_time': 'mean'
        }).round(4)
        
        print(mode_comparison)
        
        # æ¨¡å¼æ•ˆæœåˆ†æ
        print("\nğŸ“Š æ¨¡å¼æ•ˆæœå°æ¯”")
        print("-" * 30)
        
        for mode in df['pipeline_mode'].unique():
            mode_data = df[df['pipeline_mode'] == mode]
            avg_mae = mode_data['val_mae'].mean()
            avg_r2 = mode_data['val_r2'].mean()
            avg_time = mode_data['training_time'].mean()
            count = len(mode_data)
            
            print(f"{mode:15} | MAE: {avg_mae:.4f} | RÂ²: {avg_r2:.4f} | æ™‚é–“: {avg_time:.2f}s | æ¨£æœ¬: {count}")
    
    def create_visualization(self, df: pd.DataFrame):
        """å‰µå»ºè¦–è¦ºåŒ–åœ–è¡¨"""
        print("\nğŸ¨ ç”Ÿæˆè¦–è¦ºåŒ–å ±å‘Š...")
        
        # è¨­å®šåœ–å½¢å¤§å°
        fig, axes = plt.subplots(2, 3, figsize=(20, 12))
        fig.suptitle('AQIé æ¸¬ç³»çµ± - æ¨¡å‹æ€§èƒ½åˆ†æå ±å‘Š', fontsize=16, fontweight='bold')
        
        # 1. æ¨¡å‹MAEæ¯”è¼ƒ
        ax1 = axes[0, 0]
        model_mae = df.groupby('model')['val_mae'].mean().sort_values()
        model_mae.plot(kind='bar', ax=ax1, color=['#FF6B6B', '#4ECDC4'])
        ax1.set_title('æ¨¡å‹MAEæ¯”è¼ƒ', fontweight='bold')
        ax1.set_ylabel('MAE')
        ax1.tick_params(axis='x', rotation=45)
        
        # 2. æ¨¡å‹RÂ²æ¯”è¼ƒ
        ax2 = axes[0, 1]
        model_r2 = df.groupby('model')['val_r2'].mean().sort_values(ascending=False)
        model_r2.plot(kind='bar', ax=ax2, color=['#45B7D1', '#96CEB4'])
        ax2.set_title('æ¨¡å‹RÂ²æ¯”è¼ƒ', fontweight='bold')
        ax2.set_ylabel('RÂ²')
        ax2.tick_params(axis='x', rotation=45)
        
        # 3. è¨“ç·´æ™‚é–“æ¯”è¼ƒ
        ax3 = axes[0, 2]
        model_time = df.groupby('model')['training_time'].mean().sort_values()
        model_time.plot(kind='bar', ax=ax3, color=['#FECA57', '#FF9FF3'])
        ax3.set_title('æ¨¡å‹è¨“ç·´æ™‚é–“æ¯”è¼ƒ', fontweight='bold')
        ax3.set_ylabel('æ™‚é–“ (ç§’)')
        ax3.tick_params(axis='x', rotation=45)
        
        # 4. Pipelineæ¨¡å¼æ•ˆæœ
        ax4 = axes[1, 0]
        mode_mae = df.groupby('pipeline_mode')['val_mae'].mean().sort_values()
        mode_mae.plot(kind='bar', ax=ax4, color=['#6C5CE7', '#A29BFE'])
        ax4.set_title('Pipelineæ¨¡å¼MAEæ¯”è¼ƒ', fontweight='bold')
        ax4.set_ylabel('MAE')
        ax4.tick_params(axis='x', rotation=45)
        
        # 5. MAE vs RÂ² æ•£é»åœ–
        ax5 = axes[1, 1]
        colors = {'lightgbm': '#FF6B6B', 'lstm': '#4ECDC4'}
        for model in df['model'].unique():
            model_data = df[df['model'] == model]
            ax5.scatter(model_data['val_mae'], model_data['val_r2'], 
                       alpha=0.6, label=model, color=colors.get(model, '#999999'))
        ax5.set_xlabel('MAE')
        ax5.set_ylabel('RÂ²')
        ax5.set_title('MAE vs RÂ² åˆ†å¸ƒ', fontweight='bold')
        ax5.legend()
        
        # 6. æ¸¬ç«™æ€§èƒ½ç†±åŠ›åœ– (Top 15)
        ax6 = axes[1, 2]
        station_pivot = df.pivot_table(values='val_mae', index='station', columns='model', aggfunc='mean')
        station_pivot_top = station_pivot.head(15)  # åªé¡¯ç¤ºå‰15å€‹æ¸¬ç«™
        
        if not station_pivot_top.empty:
            sns.heatmap(station_pivot_top, annot=True, fmt='.3f', cmap='RdYlBu_r', ax=ax6)
            ax6.set_title('æ¸¬ç«™MAEç†±åŠ›åœ– (Top 15)', fontweight='bold')
        
        plt.tight_layout()
        
        # ä¿å­˜åœ–è¡¨
        output_path = self.reports_dir / "model_analysis_report.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"âœ… è¦–è¦ºåŒ–å ±å‘Šå·²ä¿å­˜: {output_path}")
        
        plt.show()
    
    def generate_summary_report(self, df: pd.DataFrame):
        """ç”Ÿæˆç¸½çµå ±å‘Š"""
        print("\n" + "="*60)
        print("ğŸ“‹ ç¸½çµå ±å‘Š")
        print("="*60)
        
        total_experiments = len(df)
        unique_stations = df['station'].nunique()
        unique_modes = df['pipeline_mode'].nunique()
        
        print(f"ğŸ”¢ ç¸½å¯¦é©—æ•¸é‡: {total_experiments}")
        print(f"ğŸ¢ æ¶µè“‹æ¸¬ç«™æ•¸: {unique_stations}")
        print(f"âš™ï¸ æ¸¬è©¦æ¨¡å¼æ•¸: {unique_modes}")
        
        # æ¨¡å‹å‹ç‡åˆ†æ
        print("\nğŸ† æ¨¡å‹å‹ç‡åˆ†æ")
        print("-" * 30)
        
        station_best = df.loc[df.groupby('station')['val_mae'].idxmin()]
        model_wins = station_best['model'].value_counts()
        print(model_wins)
        
        # æ¨è–¦é…ç½®
        print("\nğŸ’¡ æ¨è–¦é…ç½®")
        print("-" * 30)
        
        # æ‰¾å‡ºè¡¨ç¾æœ€ç©©å®šçš„é…ç½®
        config_stats = df.groupby(['pipeline_mode', 'model']).agg({
            'val_mae': ['mean', 'std'],
            'val_r2': 'mean',
            'training_time': 'mean'
        })
        
        # è¨ˆç®—ç¶œåˆåˆ†æ•¸ (ä½MAE + é«˜RÂ² + ä½è®Šç•°)
        config_stats['score'] = (
            1 / config_stats[('val_mae', 'mean')] * 100 +  # MAEè¶Šä½è¶Šå¥½
            config_stats[('val_r2', 'mean')] * 100 +       # RÂ²è¶Šé«˜è¶Šå¥½
            1 / (config_stats[('val_mae', 'std')] + 0.001)  # è®Šç•°è¶Šä½è¶Šå¥½
        )
        
        best_config = config_stats.sort_values('score', ascending=False).index[0]
        print(f"æœ€ä½³é…ç½®: {best_config[0]} + {best_config[1]}")
        
        # ç”ŸæˆJSONå ±å‘Š
        summary = {
            'analysis_timestamp': pd.Timestamp.now().isoformat(),
            'total_experiments': int(total_experiments),
            'unique_stations': int(unique_stations),
            'unique_modes': int(unique_modes),
            'model_performance': {
                model: {
                    'avg_mae': float(df[df['model'] == model]['val_mae'].mean()),
                    'avg_r2': float(df[df['model'] == model]['val_r2'].mean()),
                    'avg_training_time': float(df[df['model'] == model]['training_time'].mean()),
                    'sample_count': int(len(df[df['model'] == model]))
                }
                for model in df['model'].unique()
            },
            'best_configuration': {
                'pipeline_mode': best_config[0],
                'model': best_config[1],
                'score': float(config_stats.loc[best_config, 'score'])
            },
            'model_wins': model_wins.to_dict()
        }
        
        # ä¿å­˜å ±å‘Š
        report_path = self.reports_dir / "summary_analysis_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… ç¸½çµå ±å‘Šå·²ä¿å­˜: {report_path}")
    
    def run_analysis(self):
        """åŸ·è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ é–‹å§‹å ±å‘Šåˆ†æ...")
        
        # è¼‰å…¥æ•¸æ“š
        self.load_all_reports()
        
        if not self.data:
            print("âŒ æ²’æœ‰æ‰¾åˆ°å¯åˆ†æçš„å ±å‘Šæ•¸æ“š")
            return
        
        # å‰µå»ºDataFrame
        df = self.create_comparison_dataframe()
        print(f"ğŸ“Š åˆ†ææ•¸æ“šå½¢ç‹€: {df.shape}")
        
        # åŸ·è¡Œå„ç¨®åˆ†æ
        self.analyze_model_performance(df)
        self.analyze_station_performance(df)
        self.analyze_pipeline_modes(df)
        
        # ç”Ÿæˆè¦–è¦ºåŒ–
        self.create_visualization(df)
        
        # ç”Ÿæˆç¸½çµå ±å‘Š
        self.generate_summary_report(df)
        
        print("\nğŸ‰ åˆ†æå®Œæˆï¼")

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(description="AQIé æ¸¬ç³»çµ±å ±å‘Šåˆ†æå™¨")
    parser.add_argument(
        "--reports-dir", 
        default="outputs/reports",
        help="å ±å‘Šç›®éŒ„è·¯å¾‘ (é»˜èª: outputs/reports)"
    )
    
    args = parser.parse_args()
    
    analyzer = ReportAnalyzer(args.reports_dir)
    analyzer.run_analysis()

if __name__ == "__main__":
    main() 