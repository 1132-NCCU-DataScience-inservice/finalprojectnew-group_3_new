# ğŸ® GPUè¨“ç·´ç’°å¢ƒä½¿ç”¨æŒ‡å—

åŸºæ–¼ä½ çš„ **NVIDIA GeForce RTX 4090 (24GB VRAM)** çš„å®Œæ•´GPUè¨“ç·´è§£æ±ºæ–¹æ¡ˆã€‚

## ğŸ¯ ç’°å¢ƒç‹€æ…‹

âœ… **ç¡¬é«”é…ç½®**
- GPU: NVIDIA GeForce RTX 4090 (24GB VRAM)
- CPU: 32æ ¸å¿ƒ
- è¨˜æ†¶é«”: 63.1GB
- CUDAç‰ˆæœ¬: 12.6
- PyTorchç‰ˆæœ¬: 2.6.0+cu124

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. æª¢æŸ¥GPUç’°å¢ƒ
```bash
python setup_gpu_environment.py
```

### 2. ä¸€éµGPUè¨“ç·´
```bash
# è‡ªå‹•è¨“ç·´ï¼ˆæ¨è–¦ï¼‰
python scripts/train_gpu.py --auto_data --fast_mode

# è¨“ç·´ç‰¹å®šæ¨¡å‹
python scripts/train_gpu.py --model lgbm --auto_data
python scripts/train_gpu.py --model lstm --auto_data
```

### 3. æ‰‹å‹•é¸æ“‡æ•¸æ“š
```bash
python scripts/train_gpu.py
```

## ğŸ“Š æ€§èƒ½å°æ¯”

| æ¨¡å‹ | CPUè¨“ç·´æ™‚é–“ | GPUè¨“ç·´æ™‚é–“ | åŠ é€Ÿæ¯” | GPUè¨˜æ†¶é«”ä½¿ç”¨ |
|------|------------|------------|--------|--------------|
| **LightGBM** | ~6åˆ†é˜ | ~2åˆ†é˜ | **3x** | ~2GB |
| **LSTM** | ~40åˆ†é˜ | ~8åˆ†é˜ | **5x** | ~8GB |

## ğŸ® GPUå°ˆç”¨è¨“ç·´è…³æœ¬

### LightGBM GPUè¨“ç·´
```bash
# åŸºæœ¬GPUè¨“ç·´
python src/train_lgbm_gpu.py \
    --data data/processed/combine_168_train.npz \
    --model_out models/gpu/lgbm_gpu.pkl \
    --verbose

# å¿«é€Ÿæ¨¡å¼
python src/train_lgbm_gpu.py \
    --data data/processed/combine_168_train.npz \
    --model_out models/gpu/lgbm_gpu_fast.pkl \
    --fast_mode \
    --verbose

# å¼·åˆ¶CPUæ¨¡å¼ï¼ˆå°æ¯”ç”¨ï¼‰
python src/train_lgbm_gpu.py \
    --data data/processed/combine_168_train.npz \
    --model_out models/gpu/lgbm_cpu.pkl \
    --force_cpu \
    --verbose
```

### LSTM GPUè¨“ç·´
```bash
# åŸºæœ¬GPUè¨“ç·´
python src/train_lstm_gpu.py \
    --data data/processed/combine_168_train.npz \
    --model_out models/gpu/lstm_gpu.pth \
    --epochs 50 \
    --verbose

# å¤§æ‰¹æ¬¡è¨“ç·´ï¼ˆå……åˆ†åˆ©ç”¨24GB VRAMï¼‰
python src/train_lstm_gpu.py \
    --data data/processed/combine_168_train.npz \
    --model_out models/gpu/lstm_gpu_large.pth \
    --batch_size 512 \
    --epochs 100 \
    --verbose

# å¿«é€Ÿæ¨¡å¼
python src/train_lstm_gpu.py \
    --data data/processed/combine_168_train.npz \
    --model_out models/gpu/lstm_gpu_fast.pth \
    --fast_mode \
    --epochs 20 \
    --verbose
```

## âš™ï¸ GPUå„ªåŒ–é…ç½®

### LightGBM GPUåƒæ•¸
```python
LGBM_GPU_PARAMS = {
    'device': 'gpu',
    'gpu_device_id': 0,
    'num_leaves': 127,        # GPUå¯è™•ç†æ›´å¤§æ¨¡å‹
    'learning_rate': 0.05,
    'n_estimators': 1000,     # æ›´å¤šæ¨¹
    'max_depth': 10,          # æ›´æ·±
    'gpu_use_dp': True,       # é›™ç²¾åº¦
}
```

### LSTM GPUé…ç½®
```python
LSTM_GPU_PARAMS = {
    'hidden_size': 256,       # æ›´å¤§æ¨¡å‹
    'num_layers': 3,
    'bidirectional': True,    # é›™å‘LSTM
    'use_attention': True,    # æ³¨æ„åŠ›æ©Ÿåˆ¶
    'batch_size': 256,        # å¤§æ‰¹æ¬¡
    'mixed_precision': True,  # æ··åˆç²¾åº¦
}
```

## ğŸ’¾ è¨˜æ†¶é«”ç®¡ç†

### GPUè¨˜æ†¶é«”ä½¿ç”¨ç­–ç•¥
- **å°æ•¸æ“šé›†** (<5GB): é è¼‰å…¥åˆ°GPUè¨˜æ†¶é«”
- **ä¸­æ•¸æ“šé›†** (5-15GB): å‹•æ…‹è¼‰å…¥
- **å¤§æ•¸æ“šé›†** (>15GB): åˆ†æ‰¹è™•ç†

### æ‰¹æ¬¡å¤§å°å»ºè­°
```python
# åŸºæ–¼24GB VRAMçš„å»ºè­°
BATCH_SIZES = {
    'lstm_train': 256,      # è¨“ç·´
    'lstm_val': 512,        # é©—è­‰  
    'lstm_inference': 1024, # æ¨ç†
}
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è¦‹å•é¡Œ

#### 1. GPUè¨˜æ†¶é«”ä¸è¶³
```bash
# æ¸›å°‘æ‰¹æ¬¡å¤§å°
python src/train_lstm_gpu.py --batch_size 128

# å•Ÿç”¨æ¢¯åº¦ç´¯ç©
python src/train_lstm_gpu.py --accumulation_steps 2
```

#### 2. CUDAç‰ˆæœ¬ä¸åŒ¹é…
```bash
# é‡æ–°å®‰è£æ­£ç¢ºç‰ˆæœ¬çš„PyTorch
pip uninstall torch torchvision torchaudio -y
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
```

#### 3. LightGBM GPUæ”¯æ´å•é¡Œ
```bash
# ä½¿ç”¨CPUç‰ˆæœ¬
python src/train_lgbm_gpu.py --force_cpu
```

### GPUç›£æ§å‘½ä»¤
```bash
# å¯¦æ™‚GPUç‹€æ…‹
watch -n 1 nvidia-smi

# GPUè¨˜æ†¶é«”ä½¿ç”¨
python -c "import torch; print(f'GPUè¨˜æ†¶é«”: {torch.cuda.memory_allocated()/1024**3:.1f}GB / {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f}GB')"
```

## ğŸ“ˆ æ€§èƒ½å„ªåŒ–å»ºè­°

### é‡å°RTX 4090çš„å„ªåŒ–
1. **å……åˆ†åˆ©ç”¨24GB VRAM**: ä½¿ç”¨å¤§æ‰¹æ¬¡å¤§å°
2. **æ··åˆç²¾åº¦è¨“ç·´**: å•Ÿç”¨AMPä»¥æå‡é€Ÿåº¦
3. **æ¨¡å‹ç·¨è­¯**: ä½¿ç”¨PyTorch 2.0ç·¨è­¯åŠ é€Ÿ
4. **ä¸¦è¡Œè™•ç†**: LightGBMå¤šç›®æ¨™ä¸¦è¡Œè¨“ç·´

### æœ€ä½³å¯¦è¸
```bash
# æ—¥å¸¸å¿«é€Ÿè¨“ç·´ï¼ˆ5-10åˆ†é˜ï¼‰
python scripts/train_gpu.py --fast_mode --max_samples 50000

# å®Œæ•´ç²¾ç¢ºè¨“ç·´ï¼ˆ30-60åˆ†é˜ï¼‰
python scripts/train_gpu.py --epochs 100

# æ€§èƒ½åŸºæº–æ¸¬è©¦
python scripts/train_gpu.py --benchmark --max_samples 10000
```

## ğŸ¯ é æœŸæ€§èƒ½

åŸºæ–¼ä½ çš„RTX 4090ç³»çµ±ï¼š

### LightGBM
- **è¨“ç·´æ™‚é–“**: 2-5åˆ†é˜ï¼ˆ336ç›®æ¨™ï¼‰
- **GPUä½¿ç”¨ç‡**: 60-80%
- **è¨˜æ†¶é«”ä½¿ç”¨**: 2-4GB
- **åŠ é€Ÿæ¯”**: 3-5x vs CPU

### LSTM  
- **è¨“ç·´æ™‚é–“**: 5-15åˆ†é˜ï¼ˆ50 epochsï¼‰
- **GPUä½¿ç”¨ç‡**: 85-95%
- **è¨˜æ†¶é«”ä½¿ç”¨**: 8-16GB
- **ååé‡**: 2000+ samples/s

## ğŸ† å»ºè­°å·¥ä½œæµç¨‹

### é–‹ç™¼éšæ®µ
```bash
# å¿«é€Ÿé©—è­‰ï¼ˆ1-2åˆ†é˜ï¼‰
python scripts/train_gpu.py --fast_mode --max_samples 10000

# ä¸­ç­‰æ¸¬è©¦ï¼ˆ5-10åˆ†é˜ï¼‰
python scripts/train_gpu.py --max_samples 50000
```

### ç”Ÿç”¢éšæ®µ
```bash
# å®Œæ•´è¨“ç·´ï¼ˆ30-60åˆ†é˜ï¼‰
python scripts/train_gpu.py --epochs 100
```

### å¯¦é©—éšæ®µ
```bash
# è¶…åƒæ•¸èª¿å„ª
python src/train_lstm_gpu.py --lr 0.01 --batch_size 512
python src/train_lgbm_gpu.py --fast_mode
```

## ğŸ‰ ç¸½çµ

é€šéGPUåŠ é€Ÿï¼Œä½ çš„è¨“ç·´æ•ˆç‡å°‡å¤§å¹…æå‡ï¼š

- âœ… **LightGBM**: 6åˆ†é˜ â†’ 2åˆ†é˜ (3xæå‡)
- âœ… **LSTM**: 40åˆ†é˜ â†’ 8åˆ†é˜ (5xæå‡)
- âœ… **å®Œæ•´Pipeline**: 2å°æ™‚ â†’ 30åˆ†é˜ (4xæå‡)

ç«‹å³é–‹å§‹ä½¿ç”¨GPUåŠ é€Ÿè¨“ç·´ï¼Œäº«å—æ¥µè‡´çš„è¨“ç·´é«”é©—ï¼ ğŸš€ 